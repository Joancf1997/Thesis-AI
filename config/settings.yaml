# llm:
#   provider: ollama
#   model_name: llama2.3
#   temperature: 0
#   max_tokens: 2048
llm:
  provider: openai
  model_name: gpt-5.2
  temperature: 0
  max_tokens: 2048
